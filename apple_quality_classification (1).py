# -*- coding: utf-8 -*-
"""Apple Quality Classification.ipynb

Automatically generated by Colab.

Original file is located at
    https://colab.research.google.com/drive/1qA_IrqGMC8EfGM2WcVKxqbBZU_fCTANn

# Predictive Analytics: Apple Quality Classification

# Deskripsi Proyek

# Latar Belakang Proyek Klasifikasi Kualitas Apel dengan Machine Learning

# 1. Import Library
Mengimpor library yang akan digunakan dalam pembuatan proyek ini
"""

import pandas as pd
import numpy as np
import seaborn as sns
import matplotlib.pyplot as plt
import warnings
import time
warnings.filterwarnings("ignore", category=FutureWarning)

!pip install lazypredict
from lazypredict.Supervised import LazyClassifier
from sklearn.model_selection import train_test_split
from sklearn.preprocessing import StandardScaler
from sklearn.neighbors import KNeighborsClassifier
from sklearn.ensemble import ExtraTreesClassifier
from lightgbm import LGBMClassifier
from sklearn.svm import SVC
from sklearn.semi_supervised import LabelSpreading
from sklearn.metrics import accuracy_score, precision_score, recall_score, f1_score

"""# 2. Data Understanding
Data Understanding adalah tahap untuk memahami dataset secara mendalam.

# Data Loading
Data loading adalah tahap memuat dataset ke dalam program agar dapat digunakan untuk proses analisis atau pemodelan.
"""

# Import module yang disediakan google colab untuk kebutuhan upload file
from google.colab import files
files.upload()

# Mengunduh Dataset dari Kaggle
!mkdir -p ~/.kaggle
!cp kaggle.json ~/.kaggle/
!chmod 600 ~/.kaggle/kaggle.json

!kaggle datasets download -d nelgiriyewithana/apple-quality
!unzip apple-quality.zip

# Membaca Data dari File CSV
apel = pd.read_csv('/content/apple_quality.csv')

"""# Exploratory Data Analysis (EDA)
Exploratory data analysis adalah tahap awal untuk memahami data, menemukan pola, serta mendeteksi anomali menggunakan statistik dan visualisasi.

* EDA - Deskripsi Variabel
"""

apel

"""* Dataset berisi 4001 baris (rows), yang masing-masing mewakili satu sampel atau data apel.

* Terdapat 9 kolom (columns) yaitu fitur dan label sebagai berikut:

  - A_id : ID unik setiap data apel.
  - Size : Ukuran apel (angka sudah dinormalisasi atau distandarisasi).
  - Weight : Berat apel.
  - Sweetness : Tingkat kemanisan apel.
  - Crunchiness : Tingkat kerenyahan apel.
  - Juiciness : Tingkat kejuiciness/apel berair.
  - Ripeness : Tingkat kematangan apel.
  - Acidity : Tingkat keasaman apel.
  - Quality : Kualitas apel dalam kategori good atau bad.
"""

apel.info()

"""Dari kode di atas dapat disimpulkan bahwa:

- Dataset memiliki 7 kolom dengan tipe data float64, yaitu A_id, Size, Weight, Sweetness, Crunchiness, Juiciness, dan Ripeness, serta 2 kolom dengan tipe data object, yaitu Acidity dan Quality.

- Kolom A_id akan dihapus (drop) karena tidak akan digunakan dalam proyek ini.

- Kolom Acidity yang awalnya bertipe object akan dikonversi menjadi tipe data float64 agar sesuai dengan jenis data numerik lainnya.
"""

# Ringkasan Statistik Deskriptif Data Numerik
apel.describe()

"""Dari data di atas dapat disimpulkan:

- count menunjukkan jumlah data valid, yaitu 4000 per kolom.

- mean adalah rata-rata nilai tiap kolom, dengan nilai sekitar nol, menunjukkan data mungkin sudah distandarisasi.

- std menggambarkan sebaran data di sekitar rata-rata.

- min dan max menunjukkan rentang nilai terkecil dan terbesar.

- 25% (Q1), 50% (median), dan 75% (Q3) menunjukkan distribusi data dalam persentil.
"""

apel.shape

"""dataset tersebut memiliki 4001 baris data dan 9 kolom fitur

* EDA - Menangani Missing Value dan Outliers
"""

# melihat jumlah duplikat data
apel.duplicated().sum()

"""jika dilihat dari output yang dihasilkan dapat disimpulkan bahwa tidak terdapat data yang terduplikat"""

# melihat jumlah missing value
apel.isnull().sum()

"""Setelah dilakukan pengecekan, dapat disimpulkan bahwa setiap kolom memiliki 1 nilai yang hilang (missing value), kecuali kolom Acidity yang tidak memiliki missing value."""

# deteksi outliers
apel_outlier=apel.select_dtypes(exclude=['object'])
for column in apel_outlier:
        plt.figure()
        sns.boxplot(data=apel_outlier, x=column)

"""* EDA - Univariate Analysis

adalah nalisis data dengan fokus pada satu variabel saja untuk memahami distribusi, pola, dan karakteristiknya.
Biasanya dilakukan dengan menggunakan statistik deskriptif dan visualisasi seperti histogram, boxplot, atau bar chart.
"""

# Membuat histogram untuk melihat sebaran nilai pada setiap fitur numerik dalam dataset apel
apel.hist(bins=50, figsize=(20,15))
plt.show()

"""- EDA - Multivariate Analysis

adalah analisis data yang melibatkan dua atau lebih variabel sekaligus untuk melihat hubungan, korelasi, atau pola antar fitur.
Biasanya menggunakan visualisasi seperti scatter plot, heatmap korelasi, atau pairplot.
"""

# Visualisasi Hubungan Antar Variabel dengan Pairplot
sns.pairplot(apel, diag_kind = 'kde')

# Visualisasi Matriks Korelasi dengan Heatmap
plt.figure(figsize=(10, 8))
correlation_matrix = apel.select_dtypes(include=['number']).corr().round(2)

sns.heatmap(data=correlation_matrix, annot=True, cmap='coolwarm', linewidths=0.5)
plt.title("Matriks Korelasi untuk Fitur Numerik", size=20)
plt.show()

"""# 3. Data Preparation
Data Preparation merupakan tahap untuk mempersiapkan data sebelum masuk ke tahap pembuatan model Machine Learning.

# Data Cleaning

# 1. Menghapus kolom
"""

# drop kolom
apel.drop("A_id",axis=1,inplace=True)

"""kolom A_id dihapus dari DataFrame karena kolom tersebut tidak akan digunakan dalam proyek ini.
Kolom ini kemungkinan hanya berisi ID atau penanda unik yang tidak memiliki pengaruh terhadap proses analisis atau pemodelan, sehingga dihilangkan untuk menyederhanakan data.

# 2. Menangani missing value
"""

# membersihkan data dari missing value
apel.dropna(inplace=True)
apel.isnull().sum().sum()

"""# 3. Mengubah tipe data"""

# mengubah tipe data
apel["Acidity"] = apel["Acidity"].astype("float64")

"""Kode itu mengubah tipe data kolom Acidity menjadi angka desimal (float64) supaya bisa diproses secara matematis."""

apel.info()

"""# 4. Encoding Label Target"""

# label encoding
apel["Quality"] = apel["Quality"].map({"bad":0, "good":1})

"""Kode ini dilakukan untuk mengubah data kategori pada kolom Quality menjadi angka (0 dan 1) agar bisa diproses oleh model machine learning."""

apel.shape

"""# 5. Menangani Outlier"""

# menangani outlier dengan menggunakan metode IQR
apel_numeric = apel.select_dtypes(include=['number'])

Q1 = apel_numeric.quantile(0.25)
Q3 = apel_numeric.quantile(0.75)
IQR = Q3 - Q1

apel_clean = apel[~((apel_numeric < (Q1 - 1.5 * IQR)) | (apel_numeric > (Q3 + 1.5 * IQR))).any(axis=1)]

"""Kode ini menghapus data yang memiliki nilai ekstrem (outlier) dengan menggunakan metode IQR, yaitu membuang data yang berada di luar rentang normal antara kuartil pertama dan ketiga. Hal ini dilakukan supaya hasil analisis dan model menjadi lebih akurat dan stabil."""

apel_clean.shape

"""# 6. Memisahkan fitur dan target"""

# Memisahkan Fitur dan Target Variabel
X = apel_clean.drop("Quality",axis=1)
y = apel_clean.Quality

"""Kode ini memisahkan data input (fitur) dan data output (target) supaya model tahu apa yang dipakai untuk belajar dan apa yang harus diprediksi.

# 7. Train-Test-Split
"""

X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42)
y_test = y_test.to_numpy()

print(f'Total datasets: {len(X)}')
print(f'Total data Latih: {len(X_train)}')
print(f'Total data Uji: {len(X_test)}')

"""Kode ini membagi data menjadi 80% untuk pelatihan dan 20% untuk pengujian, lalu menampilkan jumlah data total, data latih, dan data uji.

# 8. Normalisasi
"""

sc = StandardScaler()
X_train = sc.fit_transform(X_train)
X_test = sc.transform(X_test)

"""code diatas melakukan standardisasi data fitur supaya setiap kolom punya rata-rata 0 dan standar deviasi 1. Ini penting agar model machine learning bekerja lebih optimal dan tidak bias pada fitur dengan skala besar.

# 4. Model Development

# Lazy classifier

Lazy classifier adalah jenis algoritma pembelajaran mesin yang tidak melakukan proses pelatihan (training) secara eksplisit sebelum digunakan untuk prediksi. Dengan kata lain, algoritma ini tidak membangun model secara langsung dari data pelatihan, melainkan menyimpan data tersebut dan baru melakukan perhitungan atau komputasi saat menerima data baru untuk diklasifikasikan.

*  Kelebihan
1. Tidak Memerlukan Proses Pelatihan yang Intensif
2. Fleksibilitas dalam Penambahan Data Baru
3. Simpel dan Mudah Diimplementasikan

*  Kekurangan
1. Waktu Prediksi yang Relatif Lambat
2. Memerlukan Memori Besar
3. Rentan terhadap Noise dan Data Tidak Relevan
4. Tidak Melakukan Generalisasi Model Secara Eksplisit
"""

# Membandingkan performa berbagai model klasifikasi secara otomatis dengan bantuan library LazyPredict.
clf = LazyClassifier()
models,predicts = clf.fit(X_train,X_test,y_train,y_test)
print(models.sort_values(by="Accuracy",ascending=False))

# Visualisasi akurasi model klasifikasi
temp = models.sort_values(by="Accuracy",ascending=True)
plt.figure(figsize=(10, 8))
plt.barh(temp.index,temp["Accuracy"])
plt.show()

# menyiapkan tabel evaluasi
models = pd.DataFrame(index=['accuracy', 'precision', 'recall', 'f1_score'],
                      columns=['KNN', 'ExtraTreesClassifier', 'LGBMClassifier', 'SVC', 'LabelSpreading'])

# Melatih model KNN
knn = KNeighborsClassifier(n_neighbors=5, weights='distance')
knn.fit(X_train, y_train)
knn_pred = knn.predict(X_test)

models.loc['accuracy','KNN'] = accuracy_score(y_test, knn_pred)
models.loc['precision','KNN'] = precision_score(y_test, knn_pred, average='weighted')
models.loc['recall','KNN'] = recall_score(y_test, knn_pred, average='weighted')
models.loc['f1_score','KNN'] = f1_score(y_test, knn_pred, average='weighted')

# Melatih model ExtraTreesClassifier
etc = ExtraTreesClassifier(n_estimators=100, max_depth= 10, n_jobs= 2, random_state= 100)
etc.fit(X_train, y_train)
etc_pred = etc.predict(X_test)

models.loc['accuracy','ExtraTreesClassifier'] = accuracy_score(y_test, etc_pred)
models.loc['precision','ExtraTreesClassifier'] = precision_score(y_test, etc_pred, average='weighted')
models.loc['recall','ExtraTreesClassifier'] = recall_score(y_test, etc_pred, average='weighted')
models.loc['f1_score','ExtraTreesClassifier'] = f1_score(y_test, etc_pred, average='weighted')

# Melatih model LGBMClassifier
lgbm = LGBMClassifier(n_estimators=100, max_depth= 10, n_jobs= 2, random_state= 100)
lgbm.fit(X_train, y_train)
lgbm_pred = lgbm.predict(X_test)

models.loc['accuracy','LGBMClassifier'] = accuracy_score(y_test, lgbm_pred)
models.loc['precision','LGBMClassifier'] = precision_score(y_test, lgbm_pred, average='weighted')
models.loc['recall','LGBMClassifier'] = recall_score(y_test, lgbm_pred, average='weighted')
models.loc['f1_score','LGBMClassifier'] = f1_score(y_test, lgbm_pred, average='weighted')

# Melatih model dengan SVC(Support Vector Classifier)
svc = SVC()
svc.fit(X_train, y_train)
svc_pred = svc.predict(X_test)

models.loc['accuracy','SVC'] = accuracy_score(y_test, svc_pred)
models.loc['precision','SVC'] = precision_score(y_test, svc_pred, average='weighted')
models.loc['recall','SVC'] = recall_score(y_test, svc_pred, average='weighted')
models.loc['f1_score','SVC'] = f1_score(y_test, svc_pred, average='weighted')

# Melatih Model Dengan LabelSpreading
lbs = LabelSpreading()
lbs.fit(X_train, y_train)
lbs_pred = lbs.predict(X_test)

models.loc['accuracy','LabelSpreading'] = accuracy_score(y_test, lbs_pred)
models.loc['precision','LabelSpreading'] = precision_score(y_test, lbs_pred, average='weighted')
models.loc['recall','LabelSpreading'] = recall_score(y_test, lbs_pred, average='weighted')
models.loc['f1_score','LabelSpreading'] = f1_score(y_test, lbs_pred, average='weighted')

"""# 5. Evaluasi Model

# Score Model
"""

# Melihat akurasi model
print(models)

"""Dari tabel diatas dapat disimpulkan bahwa:

- KNN memiliki nilai tertinggi di semua metrik, yaitu 0.89 (atau 89%), menandakan performa terbaik.

- ExtraTreesClassifier paling rendah, dengan nilai sekitar 0.85 (85%).

- Model lain (LGBMClassifier, SVC, LabelSpreading) berkisar di angka 0.88 (88%).

# Plot Model
"""

# Menampilkan grafik batang (bar chart) yang membandingkan akurasi beberapa model klasifikasi.
temp = models.loc['accuracy'].sort_values(ascending=True)
colors = plt.cm.Paired(range(len(temp)))

plt.figure(figsize=(10, 6))
plt.bar(temp.index, temp.values, color=colors)
plt.ylabel('Accuracy')
plt.title('Perbandingan Akurasi Model')
plt.ylim(0, 1.1)
plt.grid(axis='y', linestyle='--', alpha=0.7)
plt.tight_layout()
plt.show()